{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_algorithm_names(df):\n",
    "    algorithm_names=[]\n",
    "    for column_headers in df.columns:\n",
    "        strsplit= column_headers.split(\"_\")\n",
    "        if len(strsplit)>1:\n",
    "            if strsplit[1] not in algorithm_names:\n",
    "                algorithm_names.append(strsplit[1])\n",
    "    return algorithm_names\n",
    "\n",
    "# algorithm_names=find_algorithm_names(df)\n",
    "# print(algorithm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich import box \n",
    "from sklearn import metrics\n",
    "import streamlit as st\n",
    "\n",
    "def table_setup():\n",
    "#     table = Table(title=\"\", box=box.ROUNDED)\n",
    "#     table.add_column(\"\")\n",
    "#     table.add_column(\"predicted 0\")\n",
    "#     table.add_column(\"predicted 1\")\n",
    "#     return table\n",
    "# console = Console(record=True)\n",
    "    d = {' ': [\"actual 0\", \"actual 1\"], 'predicted 0': [\"0\",\"0\"] , 'predicted 1' : [\"0\",\"0\"]}\n",
    "    dff = pd.DataFrame(data=d)\n",
    "    return dff\n",
    "def confusion_matrix_create (column_name,columnlabel):\n",
    "    y = df[\"groundTruth\"] # definite truth\n",
    "    val_count = y.value_counts()\n",
    "    total = len(y)\n",
    "#     console.rule(f\"[bold red]Confusion matrix \", align=\"left\")\n",
    "#     print(f\"Nr of occurance of:\\n{val_count}\")\n",
    "#     print(f\"total {total}\")\n",
    "    dff = table_setup()\n",
    "    X = df[column_name]\n",
    "    # continue\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y, X).ravel()\n",
    "\n",
    "    f1 = metrics.f1_score(y, X)\n",
    "\n",
    "    #print\n",
    "#     table.add_row(\"actual 0\", \"[blue]\"+str(tn), str(fp))\n",
    "#     table.add_row(\"actual 1\", str(fn), \"[blue]\"+str(tp))\n",
    "    dff['predicted 0']=[str(tn),str(fn)]\n",
    "    dff['predicted 1']= [str(fp),str(tp)]\n",
    "    \n",
    "#     console.print(f\"f1: [orange1]{f1}[/orange1]\\n\")\n",
    "    blankIndex=[''] * len(dff)\n",
    "    dff.index=blankIndex\n",
    "    columnlabel.table(dff)\n",
    "    new_title1 = '<p style=\"font-family:sans-serif; color:Black; font-size: 36px;\">'\n",
    "    format_float_f1 = \"{:.2f}\".format(f1)\n",
    "    new_title2= 'F1 score: ' + str(format_float_f1)+'</p>'\n",
    "    new_title=new_title1+new_title2\n",
    "    columnlabel.markdown(new_title, unsafe_allow_html=True)\n",
    "    print(dff)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "def ROC_create (column_name,columnlabel):\n",
    "    y = df[\"groundTruth\"] # definite truth\n",
    "    val_count = y.value_counts()\n",
    "    total = len(y)\n",
    "    \n",
    "    X = df[column_name]\n",
    "    \n",
    "    fig_roc=RocCurveDisplay.from_predictions(y, X)\n",
    "#     plt.show()\n",
    "    columnlabel.pyplot(fig_roc.figure_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(algorithm_name,columnlabel):\n",
    "    new_title1 = '<p style=\"font-family:sans-serif; color:Blue; font-size: 36px;\">'\n",
    "    new_title2= algorithm_name.capitalize()+' results</p>'\n",
    "    new_title=new_title1+new_title2\n",
    "    new_subtitle1= '<p style=\"font-family:sans-serif; color:Black; font-size: 12px; text-align: center;\">'\n",
    "    new_subtitle2= \"ROC curve \" + '</p'\n",
    "    new_subtitle3= \"Confusion matrix \"+ '</p'\n",
    "    columnlabel.markdown(new_title, unsafe_allow_html=True)\n",
    "#     st.write (algorithm_name+ \" algorithm results\")\n",
    "    columnlabel.markdown(new_subtitle1+new_subtitle2, unsafe_allow_html=True)\n",
    "    ROC_create(\"accuracy_\"+algorithm_name,columnlabel)\n",
    "    columnlabel.markdown(new_subtitle1+new_subtitle3, unsafe_allow_html=True)\n",
    "    confusion_matrix_create(\"labels_\"+algorithm_name,columnlabel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "uploaded_file = st.file_uploader(\"Choose a  CSV file\",type=['csv'])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "#read csv\n",
    "    df=pd.read_csv(uploaded_file)\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
    "    temp_test=['detectron','detectron','detectron']\n",
=======
    "    temp_test=find_algorithm_names(df)\n",
>>>>>>> Stashed changes
=======
    "    temp_test=find_algorithm_names(df)\n",
>>>>>>> Stashed changes
    "    columns= st.columns(len(temp_test),gap=\"medium\")\n",
    "    for i in range(0, len(temp_test)):\n",
    "        show_results(temp_test[i],columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
